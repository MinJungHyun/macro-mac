import json
import os
from datetime import datetime

import cv2
import mss
import pyautogui
from PIL import Image


def action(task, mouse_pos=None):
     
    action = task.get('action', 'move')
    key = task.get('key', '')
    text = task.get('text', '')
    
    
    # action ì¶œë ¥ì„ ìŠ¤í¬ë¦°ìƒ· forë¬¸ ì´ì „ìœ¼ë¡œ ì´ë™
    print(f'ğŸ¯ ì‹¤í–‰í•  ì•¡ì…˜: {action}') 
    if action == 'click': 
        print(f'ğŸ–± í´ë¦­ ìœ„ì¹˜: {mouse_pos}')
        pyautogui.click(mouse_pos['x'], mouse_pos['y']) 
        return True
    
    elif action == 'type':
        print('âŒ¨ í…ìŠ¤íŠ¸ ì…ë ¥ ì‹¤í–‰...')
        pyautogui.click(mouse_pos['x'], mouse_pos['y']) 
        pyautogui.typewrite(text)
        return True
    
    elif action == 'paste':
        print('ğŸ“‹ ë¶™ì—¬ë„£ê¸° ì‹¤í–‰...')
        pyautogui.click(mouse_pos['x'], mouse_pos['y']) 
        pyautogui.hotkey('command', 'v')
        return True
    
    elif action == 'keypress':
        print('ğŸ”‘ í‚¤ ì…ë ¥ ì‹¤í–‰...')
        pyautogui.click(mouse_pos['x'], mouse_pos['y']) 
        pyautogui.press(key)
        return True    
    
    return False

def search_move(task, screenshots, mouse_pos=None):
    image_path = task.get('image_path')
    action = task.get('action', 'move')
    key = task.get('key', 'a')
    confidence = task.get('confidence', 0.98)
    text = task.get('text', '')
    capture_size = task.get('capture_size', (200, 200))

    # ì´ì „ ë§ˆìš°ìŠ¤ ìœ„ì¹˜ ì¶œë ¥
    if mouse_pos:
        print(f'ğŸ–± ì´ì „ ë§ˆìš°ìŠ¤ ìœ„ì¹˜: {mouse_pos}')
    
    if not os.path.exists(image_path):
        print(f'âŒ ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ: {image_path}')
        return False, None

    target_img = cv2.imread(image_path)
    if target_img is None:
        print(f'âŒ íƒ€ê²Ÿ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}')
        return False, None

    target_height, target_width = target_img.shape[:2]
    print(f'ğŸ” íƒ€ê²Ÿ ì´ë¯¸ì§€: {image_path}, í¬ê¸°: {target_width}x{target_height}, ìœ ì‚¬ë„ ê¸°ì¤€: {confidence}')

    scales = [1.0]  # ì •í™•ë„ ì¤‘ì‹¬ìœ¼ë¡œ ìŠ¤ì¼€ì¼ì€ ê³ ì •

    for screen in screenshots:
        if screen['id'] != 1:  # ëª¨ë‹ˆí„° 2ë²ˆë§Œ (id=1)
            continue

        monitor_id = screen['id']
        offset_x = screen['offset_x']
        offset_y = screen['offset_y']
        screen_img = screen['cv_image']  # ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©

        try:
            for scale in scales:
                resized = cv2.resize(target_img, (0, 0), fx=scale, fy=scale)
                resized_h, resized_w = resized.shape[:2]

                result = cv2.matchTemplate(screen_img, resized, cv2.TM_CCOEFF_NORMED)
                min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)

                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

                if max_val >= confidence:
                    top_left = max_loc
                    bottom_right = (top_left[0] + resized_w, top_left[1] + resized_h)
                    center_x = top_left[0] + (resized_w // 2 )
                    center_y = top_left[1] + (resized_h // 2 )
                    abs_x = center_x 
                    abs_y = center_y

                    # ë§¤ì¹­ ìœ„ì¹˜ ë””ë²„ê¹… ì´ë¯¸ì§€ ì €ì¥
                    debug_img = screen_img.copy()
                    cv2.rectangle(debug_img, top_left, bottom_right, (0, 255, 0), 2)
                    cv2.imwrite(f'debug_matched_location_{monitor_id}_{timestamp}.png', debug_img)

                    # ì£¼ë³€ ì˜ì—­ ìº¡ì²˜ ì €ì¥
                    with mss.mss() as sct:
                        capture_width, capture_height = capture_size
                        left = max(0, abs_x - capture_width)
                        top = max(0, abs_y - capture_height)
                        region = {'left': left, 'top': top, 'width': capture_width, 'height': capture_height}
                        screenshot = sct.grab(region)
                        img = Image.frombytes('RGB', screenshot.size, screenshot.rgb)
                        capture_filename = f'found_image_{monitor_id}_{timestamp}.png'
                        img.save(capture_filename)
                        print(f'ğŸ“¸ ë°œê²¬ëœ ìœ„ì¹˜ ìº¡ì²˜ ì €ì¥: {capture_filename}')

                    # actionì— ë”°ë¥¸ ì²˜ë¦¬ - moveë§Œ ì´ë™, ë‚˜ë¨¸ì§€ëŠ” ë°”ë¡œ ì‹¤í–‰ í›„ ì¦‰ì‹œ ì¢…ë£Œ
                    result_data = {
                        'x': center_x, 'y': center_y,
                        'monitor_id': monitor_id,
                        'capture_file': capture_filename
                    }
                     
                    
                    # ê¸°ë³¸ì ìœ¼ë¡œëŠ” move ì²˜ë¦¬ 
                    print(f'ğŸ–± ê¸°ë³¸ ë§ˆìš°ìŠ¤ ì´ë™... {center_x} : {center_y} ')
                    pyautogui.moveTo(center_x, center_y)
                    return True, result_data
        except Exception as e:
            print(f'âŒ ë§¤ì¹­ ì‹¤íŒ¨ (ëª¨ë‹ˆí„° {monitor_id}): {e}')
    print(f'âŒ ì´ë¯¸ì§€ ëª» ì°¾ìŒ: {image_path}')
    return False, None
