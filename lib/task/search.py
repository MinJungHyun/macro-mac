import json
import os
from datetime import datetime
import time
import pyperclip
import cv2
import mss
import pyautogui
from PIL import Image
from lib.task.task_runner import capture_screenshots

debug_log = False

def action(task, mouse_pos=None):
     
    time.sleep(0.02)
    if debug_log == True:
        print(f'ğŸ” í˜„ì¬ì˜ ë§ˆìš°ìŠ¤ ìœ„ì¹˜: {mouse_pos["x"]}, {mouse_pos["y"]}')
    action = task.get('action', 'move')  
    
    if action == 'click':  
        # í´ë¦­ ì „ì— ë”œë ˆì´ ì¶”ê°€
        pyautogui.click(mouse_pos['x'], mouse_pos['y'])  
        return True, mouse_pos
    
    elif action == 'move':  
        offset = task.get('offset')
        pyautogui.moveRel(offset['x'], offset['y']) 
        return True, {'x': mouse_pos['x'] + offset['x'], 'y': mouse_pos['y'] + offset['y']}
    
    elif action == 'text': 
        text = task.get('text', '')
        pyautogui.typewrite(text)
        return True, mouse_pos
    
    elif action == 'paste': 
        pyautogui.hotkey('command', 'v')
        return True, mouse_pos

    elif action == 'hotkey': 
        key_combination = task.get('key_combination', [])
        pyautogui.hotkey(*key_combination)
        return True, mouse_pos
    
    
    elif action == 'keypress': 
        key = task.get('key')
        pyautogui.press(key)
        return True, mouse_pos
    
    
    elif action == 'clipboard':
        ## í´ë¦½ë³´ë“œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¨ë‹¤
        clipboard_data = pyperclip.paste()
        if debug_log == True:
            print(f'ğŸ“‹ í´ë¦½ë³´ë“œ ë°ì´í„°: {clipboard_data}')
        
        return True, {'x': mouse_pos['x'], 'y': mouse_pos['y'], 'clipboard_data': clipboard_data}
    elif action == 'sleep':
        duration = task.get('duration', 1)
        if debug_log == True:
            print(f'â³ {duration}ì´ˆ ëŒ€ê¸° ì¤‘...')
        time.sleep(duration)
        return True, mouse_pos
    else:
        if debug_log == True:
            print(f'âŒ ì•Œ ìˆ˜ ì—†ëŠ” ì•¡ì…˜: {action}')
        return False

def waiting_capture_screenshot_search(task, current_mouse_pos, max_wait_time=20, interval=1.0):
    """
    ìŠ¤í¬ë¦°ìƒ·ì„ ì£¼ê¸°ì ìœ¼ë¡œ ìº¡ì²˜í•˜ì—¬ ì›í•˜ëŠ” ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ë•Œê¹Œì§€ ëŒ€ê¸°í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        task (dict): ìˆ˜í–‰í•  ì‘ì—… ì •ë³´
        current_mouse_pos (dict): í˜„ì¬ ë§ˆìš°ìŠ¤ ìœ„ì¹˜ {'x': x, 'y': y}
        max_wait_time (int): ìµœëŒ€ ëŒ€ê¸° ì‹œê°„(ì´ˆ), ê¸°ë³¸ê°’ 20ì´ˆ
        interval (float): ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜ ê°„ê²©(ì´ˆ), ê¸°ë³¸ê°’ 1ì´ˆ
    
    Returns:
        tuple: (ì„±ê³µ ì—¬ë¶€(bool), ì°¾ì€ ìœ„ì¹˜ ì •ë³´(dict))
    """
    start_time = time.time()
    
    while True:
        # ìµœëŒ€ ëŒ€ê¸° ì‹œê°„ ì²´í¬
        if time.time() - start_time > max_wait_time:
            print(f"â° ì œí•œ ì‹œê°„ {max_wait_time}ì´ˆ ì´ˆê³¼")
            return False, None
        
        try:
            # ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜
            screenshots = capture_screenshots()
            if not screenshots:
                print('âŒ ìŠ¤í¬ë¦° ìº¡ì²˜ ì‹¤íŒ¨')
                return False, None
            
            # ì´ë¯¸ì§€ ê²€ìƒ‰ ìˆ˜í–‰
            success, pos = search(task, screenshots, current_mouse_pos)
            
            if success:
                print(f"âœ… ì´ë¯¸ì§€ '{task.get('image_path')}' ì°¾ìŒ")
                return True, pos
            
            # ì‹¤íŒ¨ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„
            print(f"ğŸ”„ ì´ë¯¸ì§€ ê²€ìƒ‰ ì¬ì‹œë„ ì¤‘... (ê²½ê³¼ ì‹œê°„: {int(time.time() - start_time)}ì´ˆ)")
            time.sleep(interval)
            
        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False, None
        
     
def search(task, screenshots, mouse_pos=None):
    image_paths = task.get('image_paths') or [task.get('image_path')]
    confidence = task.get('confidence', 0.98)
    capture_size = task.get('capture_size', (200, 200))
    find_mode = task.get('find_mode', 'first')  # 'first', 'top', 'bottom', 'left', 'right'
    if debug_log == True:
        print(f'ğŸ” ì´ë¯¸ì§€ ê²€ìƒ‰ ì‹œì‘: {image_paths}, ìœ ì‚¬ë„ ê¸°ì¤€: {confidence}, ìº¡ì²˜ í¬ê¸°: {capture_size}, ì°¾ê¸° ëª¨ë“œ: {find_mode}')

    found_matches = []

    for image_path in image_paths:
        if not os.path.exists(image_path):
            if debug_log == True:
                print(f'âŒ ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ: {image_path}')
            continue

        target_img = cv2.imread(image_path)
        if target_img is None:
            if debug_log == True:
                print(f'âŒ íƒ€ê²Ÿ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}')
            continue

        target_height, target_width = target_img.shape[:2]
        if debug_log == True:
            print(f'ğŸ” íƒ€ê²Ÿ ì´ë¯¸ì§€: {image_path}, í¬ê¸°: {target_width}x{target_height}, ìœ ì‚¬ë„ ê¸°ì¤€: {confidence}')

        scales = [1.0]
        for screen in screenshots:
            monitor_id = screen['id']
            offset_x = screen['offset_x']
            offset_y = screen['offset_y']
            screen_img = screen['cv_image']

            if debug_log == True:
                print(f'ğŸ” ëª¨ë‹ˆí„° {monitor_id}ì—ì„œ ê²€ìƒ‰ ì¤‘... (ì˜¤í”„ì…‹: {offset_x}, {offset_y})')

            try:
                for scale in scales:
                    resized = cv2.resize(target_img, (0, 0), fx=scale, fy=scale)
                    resized_h, resized_w = resized.shape[:2]

                    result = cv2.matchTemplate(screen_img, resized, cv2.TM_CCOEFF_NORMED)
                    loc = zip(*((result >= confidence).nonzero()[::-1]))

                    for pt in loc:
                        top_left = pt
                        center_x = top_left[0] + (resized_w // 2)
                        center_y = top_left[1] + (resized_h // 2)
                        absolute_x = center_x + offset_x
                        absolute_y = center_y + offset_y

                        found_matches.append({
                            'monitor_id': monitor_id,
                            'offset_x': offset_x,
                            'offset_y': offset_y,
                            'center_x': center_x,
                            'center_y': center_y,
                            'absolute_x': absolute_x,
                            'absolute_y': absolute_y,
                            'image_path': image_path,
                            'resized_w': resized_w,
                            'resized_h': resized_h,
                            'top_left': top_left,
                            'screen_img': screen_img
                        })
            except Exception as e:
                if debug_log == True:
                    print(f'âŒ ë§¤ì¹­ ì‹¤íŒ¨ (ëª¨ë‹ˆí„° {monitor_id}): {e}')

    if not found_matches:
        if debug_log == True:
            print(f'âŒ ì´ë¯¸ì§€ ëª» ì°¾ìŒ: {image_paths}')
        return False, None

    # ì°¾ì€ ìœ„ì¹˜ ì¤‘ì—ì„œ ì¡°ê±´ì— ë”°ë¼ ì„ íƒ
    if find_mode == 'top':
        found_matches.sort(key=lambda m: m['absolute_y'])
    elif find_mode == 'bottom':
        found_matches.sort(key=lambda m: m['absolute_y'], reverse=True)
    elif find_mode == 'left':
        found_matches.sort(key=lambda m: m['absolute_x'])
    elif find_mode == 'right':
        found_matches.sort(key=lambda m: m['absolute_x'], reverse=True)
    # 'first'ëŠ” ì •ë ¬í•˜ì§€ ì•ŠìŒ
    match = found_matches[0]

    monitor_id = match['monitor_id']
    offset_x = match['offset_x']
    offset_y = match['offset_y']
    center_x = match['center_x']
    center_y = match['center_y']
    absolute_x = match['absolute_x']
    absolute_y = match['absolute_y']
    image_path = match['image_path']
    resized_w = match['resized_w']
    resized_h = match['resized_h']
    top_left = match['top_left']
    screen_img = match['screen_img']

    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    debug_img = screen_img.copy()
    cv2.rectangle(debug_img, top_left, (top_left[0] + resized_w, top_left[1] + resized_h), (0, 255, 0), 2)
    cv2.putText(debug_img, f'({absolute_x}, {absolute_y})', (top_left[0], top_left[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    # cv2.imwrite(f'data/debug/debug_matched_location_{monitor_id}_{timestamp}.png', debug_img)

    with mss.mss() as sct:
        capture_width, capture_height = capture_size
        monitor_info = sct.monitors[monitor_id + 1]
        capture_left = center_x - capture_width // 2
        capture_top = center_y - capture_height // 2
        capture_left = max(0, min(capture_left, monitor_info['width'] - capture_width))
        capture_top = max(0, min(capture_top, monitor_info['height'] - capture_height))
        region = {
            'left': monitor_info['left'] + capture_left,
            'top': monitor_info['top'] + capture_top,
            'width': capture_width,
            'height': capture_height
        }
        if debug_log == True:
            print(f'   - ìº¡ì²˜ ì˜ì—­: {region}')
        screenshot = sct.grab(region)
        img = Image.frombytes('RGB', screenshot.size, screenshot.rgb)
        capture_filename = f'data/found/found_image_{monitor_id}_{timestamp}.png'
        # img.save(capture_filename)
        if debug_log == True:
            print(f'ğŸ“¸ ë°œê²¬ëœ ìœ„ì¹˜ ìº¡ì²˜ ì €ì¥: {capture_filename} (ëª¨ë‹ˆí„° {monitor_id})')

    if debug_log == True:
        print(f'ğŸ–± ë§ˆìš°ìŠ¤ ì´ë™: {absolute_x}, {absolute_y} (ëª¨ë‹ˆí„° {monitor_id})')
    pyautogui.moveTo(absolute_x, absolute_y)
    mouse_pos = {'x': absolute_x, 'y': absolute_y}
    if debug_log == True:
        print(f'ğŸ“ mouse_pos ì—…ë°ì´íŠ¸: {mouse_pos}')

    return True, {'x': absolute_x, 'y': absolute_y, 'monitor_id': monitor_id, 'capture_file': capture_filename}